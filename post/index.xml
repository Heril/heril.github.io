<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Elemental Data Science</title>
    <link>https://blog.elementaldatascience.com/post/</link>
    <description>Recent content in Posts on Elemental Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 27 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.elementaldatascience.com/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Simmulating the effects of luck in highly competivie events</title>
      <link>https://blog.elementaldatascience.com/2021/06/27/simmulating-the-effects-of-luck-in-highly-competivie-events/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2021/06/27/simmulating-the-effects-of-luck-in-highly-competivie-events/</guid>
      <description>To Be Finished
for (i in 1:length(luckfactor)) { for (j in 1:length(selected)) { for (k in 1:R) { simulationresults &amp;lt;- tibble(Skill = runif(n = N, min = minscore, max = maxscore), Luck = runif(n = N, min = minscore, max = maxscore)) %&amp;gt;% mutate(Score = Skill * (1 - luckfactor[i]) + Luck * luckfactor[i]) luckyFew &amp;lt;- simulationresults %&amp;gt;% mutate(SkillRank = N - rank(Skill) + 1, ScoreRank = N - rank(Score) + 1, SkillSelected = SkillRank &amp;lt;= selected[j] * N) %&amp;gt;% arrange(ScoreRank) %&amp;gt;% head(selected[j] * N) results[[i]][[j]][k,] &amp;lt;- c(mean(luckyFew$Skill), mean(luckyFew$Luck), sum(luckyFew$SkillSelected), luckfactor[i], selected[j]) } results[[i]][[j]] &amp;lt;- as.data.frame(results[[i]][[j]]) } results[[i]] &amp;lt;- bind_rows(results[[i]]) } results &amp;lt;- bind_rows(results) colnames(results) &amp;lt;- c(&amp;quot;Skill&amp;quot;, &amp;quot;Luck&amp;quot;, &amp;quot;SkillSelected&amp;quot;, &amp;quot;LuckFactor&amp;quot;, &amp;quot;ProportionSelected&amp;quot;) results$LuckFactor &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Multivariate Statistic Process Control method comparison Part 2: Generating   control limits and initial look </title>
      <link>https://blog.elementaldatascience.com/2021/05/26/multivariate-statistic-process-control-method-comparison-part-2-generating-control-limits-and-initial-look/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2021/05/26/multivariate-statistic-process-control-method-comparison-part-2-generating-control-limits-and-initial-look/</guid>
      <description>Earlier this year, I posted the first part of a write-up for a project I worked on during a project I worked on last year.
As a reminder, my project involved taking 4 different types of correlation, test the baseline and 8 different data shifts, generating 1000 simulations with 100 points of data each. I then compared how three different multivariate control charts, Hotelling T^2, MEWMA, and MCUSUM, were in detecting a shift while holding the false rate fixed over all simulations.
For this I use the pretty standard for in control average run length (ARL) of 300. This means, on average when the process is in control, you can expect to see an out of control data point in any 300 sequential points.</description>
    </item>
    
    <item>
      <title>Odds of winning constant probability games against one person</title>
      <link>https://blog.elementaldatascience.com/2021/04/23/odds-of-winning-constant-probability-games-against-one-person/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2021/04/23/odds-of-winning-constant-probability-games-against-one-person/</guid>
      <description>Probabilities and games.
Two simple games used to illustrate certain features of calculating probabilities are as follows:
You and a friend take turns flipping a fair coin. The first person to flip heads wins. If you go first, what are your chances of winning?
You and a friend take turns rolling a fair die with 6 sides. The first person to roll a 6 wins. If you go first, what are your chances of winning.
These end up being very similar problems, and can be generalized.
For convenience, I’ll talk about the rolling a die version. To start we’ll walk through a couple winning scenarios to look for a pattern.</description>
    </item>
    
    <item>
      <title>Using Python and Random Forest to predict Diabetes Risk.</title>
      <link>https://blog.elementaldatascience.com/2021/01/08/using-python-and-random-forest-to-predict-diabetes-risk/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2021/01/08/using-python-and-random-forest-to-predict-diabetes-risk/</guid>
      <description>Two weeks ago I wrote a post, Using R and Random Forest to predict Diabetes Risk. Since I am less experienced with using python in machine learning models, and this was a data set that worked out so nicely, I figured I would take an attempt at it.
First we need to load all the modules and functions we need to use.
import pandas as pd from matplotlib import pyplot as plt import numpy as np import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn import metrics  The next thing is just like was done in R, load the data, clean it up a bit for using scikit-learn to create a classification model, and then split our factors from our classification variable.</description>
    </item>
    
    <item>
      <title>Multivariate Statistic Process Control method comparison Part 1: Simulating   correlated data and optimizing data generation.</title>
      <link>https://blog.elementaldatascience.com/2021/01/04/multivariate-statistic-process-control-method-comparison-part-1-simulating-correlated-data-and-optimizing-data-generation/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2021/01/04/multivariate-statistic-process-control-method-comparison-part-1-simulating-correlated-data-and-optimizing-data-generation/</guid>
      <description>Time to mix it up a bit from my usual game probability related simulation. This week I want to talk about a project I worked on last year in doing simulations for Statistical Process Control.
For a brief primer, Statistical Process Control or SPC is a method used for monitoring something like a manufacturing process. It&amp;rsquo;s a form of time series analysis where you monitor results of some statistic taken from observing the process and then compare that statistic to a set of limits on a control chart to determine whether or not the distribution of that statistic has likely changed.</description>
    </item>
    
    <item>
      <title>The Effect of the Advantage/Disadvantage in Dungeons and Dragons 5E on Success, Failure and Damage</title>
      <link>https://blog.elementaldatascience.com/2020/12/28/the-effect-of-the-advantage-disadvantage-in-dungeons-and-dragons-5e-on-success-failure-and-damage/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2020/12/28/the-effect-of-the-advantage-disadvantage-in-dungeons-and-dragons-5e-on-success-failure-and-damage/</guid>
      <description>So, after my last Dungeons and Dragons post, I got asked about the Advantage/Disadvantage mechanic in Dungeons and Dragons Fifth Edition, so let’s look into that a bit.
In D&amp;amp;D, to succeed at a task, you roll a 20-sided die(d20) and with some math and checking with your Dungeon Master (DM), you determine if you succeed or not. In previous editions you would add your character’s modifier, as well as any additional bonuses or penalties due to the specific scenario. Fifth edition got rid of that except for one specific case, and instead replaced it with Advantage/Disadvantage.
Simply put, if your character is in some sort of advantageous situation when attempting a task, you get Advantage.</description>
    </item>
    
    <item>
      <title>Using R and Random Forest to predict Diabetes Risk</title>
      <link>https://blog.elementaldatascience.com/2020/12/24/using-r-and-random-forest-to-predict-diabetes-risk/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2020/12/24/using-r-and-random-forest-to-predict-diabetes-risk/</guid>
      <description>Time for something a bit different from my previous posts, but hopefully more common in the future.
I was looking through the UCI Machine Learning Repository for a couple of data sets I could use for some simple machine learning problems to try interesting problems and keep my abilities sharp. This week I found the Early Stage Diabetes Risk Prediction. This comes from a paper on early prediction of diabetes risk. The abstract goes over the methods used, indicating Random Forest as doing particularly well. Since I don’t have access to the actual paper, I wanted to try out using R to try this model out.</description>
    </item>
    
    <item>
      <title>The likelihood of getting or beating an array of stats in D&amp;D Part 2</title>
      <link>https://blog.elementaldatascience.com/2020/12/21/the-likelihood-of-getting-or-beating-an-array-of-stats-in-d-d-part-2/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2020/12/21/the-likelihood-of-getting-or-beating-an-array-of-stats-in-d-d-part-2/</guid>
      <description>So, after sharing my post from last week about probabilities and stat arrays. Now, the way I determine which array is better is clearly overly arbitrary. Under that system the standard array is better than an array of (7, 18, 18, 18, 18, 18), when in reality any player looking for maximal stats would take that over the standard array (8, 10, 12, 13, 14, 15). So maybe there is a different way to compare these.
Now the first approach would be to just take the ability modifier. Each integer from 3-18 maps to an integer from -4 to +4 that is used for almost everything in the game (except for carrying capacity, which uses the actual Strength score).</description>
    </item>
    
    <item>
      <title>The likelihood of getting or beating an array of stats in D&amp;D</title>
      <link>https://blog.elementaldatascience.com/2020/12/15/the-likelihood-of-getting-or-beating-an-array-of-stats-in-d-d/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2020/12/15/the-likelihood-of-getting-or-beating-an-array-of-stats-in-d-d/</guid>
      <description>I got involved in another conversation about Dungeons and Dragons and probabilities again. This time I saw something that I’ve seen come up in a variety of circumstances. So, let’s take this scenario.
A Dungeon Master is running a game where the players roll for their stats, and one player has suspiciously high results. The question of course is, did the player cheat with their stats, either by rolling a different way, or did they just pick the stats they wanted. Given D&amp;amp;D is a cooperative game, this can be especially frustrating to the other players at the table, as this one player has a character that is well above average for doing just about everything.</description>
    </item>
    
    <item>
      <title>Probabilities of Winning in the game Among Us</title>
      <link>https://blog.elementaldatascience.com/2020/12/07/probabilities-of-winning-in-the-game-among-us/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2020/12/07/probabilities-of-winning-in-the-game-among-us/</guid>
      <description>Back in August of this year, the game Among Us leapt in popularity. A social game where crewmates try to complete tasks while staying alive. At the same time, impostors try to kill off the innocent players while also sabotaging the crew. It’s a fun, interactive twist on in person social games such as Werewolf or Mafia.
With the interactive gameplay, rounds end when a player reports a dead body or call an emergency meeting and the remaining players get a chance to discus and potentially vote out one player.
This got me thinking, ignoring the various strategies for the game, and avoiding where impostors kill off innocent players, if players were just removed/voted off randomly, what would be the odds of a crewmate or an impostor victory, and with that, the expected win rate overall.</description>
    </item>
    
    <item>
      <title>Simulating die rolls and testing fairness using a Chi-squared test.</title>
      <link>https://blog.elementaldatascience.com/2020/11/24/simulating-die-rolls-and-testing-fairness-using-a-chi-squared-test./</link>
      <pubDate>Tue, 24 Nov 2020 21:13:14 -0500</pubDate>
      
      <guid>https://blog.elementaldatascience.com/2020/11/24/simulating-die-rolls-and-testing-fairness-using-a-chi-squared-test./</guid>
      <description>As someone who enjoys playing Dungeons and Dragons, I also get fascinated by the primitive random number generators used it them, the dice. When I talk dice with friends and internet strangers, the conversation sometimes leans towards discussing whether or not their dice are fair.
Now if you search for how to test this, you can find a few good answers to explain the various statistical tests that can be used, along with their pros and their cons, so I’m not going to do that here.
While probabilities of several dice together can get messy really quickly without having to pull out a reference for my courses in Probability, one quick and dirty way we have of checking the odds of results is using simulations, and doing large simulations of die rolls is pretty quick on modern machines.</description>
    </item>
    
  </channel>
</rss>
